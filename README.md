# I310Das2
##Analysis on the perspective API's bias
### Hypothesis and dataset 
-  Hypothesis: The API would be biased if it is applied on different languages
-  Dataset: Self-written and AI generated toxic comments in4 categories. English, Chinese, Toxic and Non-Toxic  
### Results
0.3811502 0.5532103 0.52272606 0.4977744 0.9029226 0.8364697 0.2786282 0.7701451 0.4475325 0.5566829 Toxic accuracy for English comments: 0.6
0.010618322 0.010806813 0.010555492 0.011812098 0.013320025 0.01024134 0.011560776 0.0074768066 0.010115679 0.011435116 Non-toxic accuracy for English comments: 1.0
0.3302291 0.36095104 0.09958932 0.47622904 0.36095104 0.044141594 0.1013248 0.1373533 0.47119883 0.021667719 Toxic accuracy for Chinese comments: 0.0
0.11479026 0.015079274 0.019477395 0.030977672 0.037577134 0.00816794 0.011749268 0.032156147 0.20219094 0.112746716 Non-toxic accuracy for Chinese comments: 1.0
###Analysis
Considering the fact that the model is capable of multiple language, I suppose it would be likely that it works differently on different languages. Although the data used to train includes manually marked comments, there may not be enough samples for the model to predict languages other than English. Therefore, I written some toxic comments myself in both English and Chinese. Non-toxic comments in English are generated by ChatGPT here, while the Chinese ones are also written by myself.
The results showed that for toxic comments in English, only 60% percent of the comments are considered toxic(probability >0.5), while NONE of the Chinese comments in the non-toxic set are considered toxic according to the model. It may be because of the fact that my wordings (especially in Chinese here) are usually considered more toxic in the background of online forums while they may not be that toxic in other perspectives. However. we do see significant biases here. For non-toxic contents, the model seems to be accurate. while we do need to have in mind that the low accuracy of toxic comments means that even if the model gives a number>0.5, it is still highly possible that the comment is actually toxic. 
